### "분명 어제까지 공들여 만든 대시보드가 왜 사라졌을까?"

> LBS 연구과제의 성능 측정을 위해 k6, 프로메테우스, 그라파나를 연동하는 모니터링 환경을 구축했다. 처음 접하는 도구들이라 튜토리얼을 따라가며 성공적으로 지표를 시각화했지만, 예기치 못한 문제가 발생했다. 시스템 점검을 위해 도커 컨테이너를 내렸다가 다시 올리는 순간, 정성껏 커스텀해둔 그라파나 대시보드와 설정값이 모두 초기화된 것이다. 컨테이너의 휘발성이라는 특성을 간과하여 발생한 이번 문제를 분석하고, 데이터가 사라지지 않는 영구적인 관제탑을 구축한 과정을 정리한다.
> 

**리팩토링 요약**

배경: docker-compose down -v 실행 시 그라파나 대시보드 및 설정 데이터 유실

핵심: Named Volume 적용을 통한 컨테이너 내부 데이터의 호스트 저장소 바인딩

결과: 컨테이너 생명주기와 무관한 데이터 영속성 확보 및 안정적인 모니터링 환경 조성

---

</br>

### 1. 문제 상황: "컨테이너를 내렸더니 설정이 사라졌다"

성능 테스트 도구인 k6를 통해 생성된 부하 데이터를 프로메테우스에 적재하고, 이를 그라파나 대시보드로 시각화하는 과정이었다. 테스트가 끝난 후 자원 관리 차원에서 도커 컨테이너를 중지하고 삭제했다가 다시 실행했는데, 그라파나 로그인 화면부터 대시보드 설정까지 모든 것이 초기 상태로 돌아가 있었다.

- **설정 데이터 증발:** 내가 정의한 대시보드 레이아웃, 데이터 소스 연결 정보 등이 모두 초기화됨
- **휘발성 저장소:** 도커 컨테이너 내부의 파일 시스템에 저장된 데이터가 컨테이너 삭제와 함께 소멸됨

기본적인 설치 과정에만 집중하다 보니, 컨테이너 내부에서 생성된 데이터가 호스트 시스템의 저장소와 연결되지 않은 상태였다.

---

</br>

### 2. 기술적 배경: 성능 측정의 삼각편대와 데이터 흐름

문제의 원인을 정확히 파악하기 위해서는 내가 구축한 모니터링 스택의 데이터 흐름을 이해해야 한다. 각 도구는 다음과 같은 유기적인 메커니즘으로 동작한다.

- **k6 (공격수):** 서비스에 인위적인 부하를 주어 서버가 얼마나 견딜 수 있는지 확인하는 데이터를 생성한다.
- **프로메테우스 (서기):** k6가 생성한 지표를 받아와서 시계열 데이터베이스에 시간 순서대로 기록한다.
- **그라파나 (화가):** 프로메테우스에 저장된 숫자 데이터를 사람이 읽기 쉬운 그래프나 차트로 그려주는 시각화 도구다.

발생한 데이터 유실 문제는 바로 이 과정에서 프로메테우스나 그라파나가 데이터를 기록하는 폴더를 도커 외부로 빼두지 않았기 때문에 발생했다.

---

</br>

### 3. 원인 진단: 컨테이너의 휘발성

도커 컨테이너는 본래 쓰고 버리는 일회용 소모품처럼 설계되었다. 컨테이너 내부에서 발생한 변경 사항은 해당 컨테이너의 레이어에만 기록되며, 컨테이너가 삭제되면 그 안의 모든 데이터도 함께 증발한다.

**왜 문제가 발생했나?**

- **비영속적 계층:** 그라파나는 내부적으로 SQLite 데이터베이스를 사용하여 대시보드 설정을 저장한다. 별도의 볼륨 설정을 하지 않으면 이 파일은 컨테이너 내부에 존재하게 된다.
- **명령어의 특성:** docker-compose stop은 컨테이너를 멈추기만 하지만, docker-compose down은 컨테이너 자체를 삭제한다. 특히 뒤에 붙은 -v 옵션은 도커가 관리하던 전용 저장소인 볼륨까지 싹 다 지우라는 의미다.

---

</br>

### 4. 해결 방안: 도커 볼륨을 활용한 데이터 영속화

컨테이너가 사라져도 데이터는 살아남아야 한다. 이를 위해 도커 볼륨 기능을 도입하여 컨테이너 내부의 특정 경로를 호스트 시스템의 저장 공간과 연결했다.

**Step 1. Docker Compose 설정 수정**

모든 서비스의 데이터가 개별적으로 보존될 수 있도록 volumes 옵션을 추가했다.

```yaml
services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus # 수집한 데이터 보존

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana_data:/var/lib/grafana # 커스텀 대시보드 및 설정 저장
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning

volumes:
  prometheus_data:
  grafana_data:
  # redis_data, postgres_data 등도 동일하게 관리
```

**Step 2. 데이터의 외부 마운트**

이렇게 설정하면 그라파나 컨테이너 내부의 /var/lib/grafana 경로와 도커 엔진이 관리하는 grafana_data 볼륨이 서로 연결된다. 이제 컨테이너를 수백 번 삭제하고 다시 만들어도, 설정 파일은 호스트 시스템에 안전하게 남게 된다.

---

</br>

### 5. 왜 이렇게 설계했는가?

**5.1 관찰 가능성의 안정성**

모니터링 시스템은 서비스의 상태를 증명하는 핵심 지표를 다룬다. 특히 LBS 연구과제처럼 반복적인 성능 테스트가 필요한 상황에서 대시보드 설정이 매번 초기화된다면 테스트 결과의 일관성을 보장하기 어렵다. 볼륨 설정을 통해 관찰 환경 자체를 인프라의 일부로 고정시켰다.

**5.2 상태와 로직의 분리**

도커를 다룰 때 가장 중요한 원칙 중 하나는 상태가 있는 데이터와 상태가 없는 애플리케이션을 분리하는 것이다. 애플리케이션인 컨테이너는 언제든 교체될 수 있어야 하지만, 데이터는 영구 저장소에 머물러야 한다.

---

</br>

### 6. 결론: "인프라는 사라져도 데이터는 남아야 한다"

처음 접하는 k6, 프로메테우스, 그라파나 스택을 구축하는 데 급급해 도커의 가장 기본적인 특성인 휘발성을 간과했다. 이번 실수를 통해 인프라 구축 시 데이터가 생성되고 소멸되는 지점이 어디인지 명확히 파악하는 것이 얼마나 중요한지 깨달았다.
