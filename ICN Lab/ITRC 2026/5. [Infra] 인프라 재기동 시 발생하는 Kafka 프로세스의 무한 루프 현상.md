실시간 위치 데이터 처리 시스템을 구축하며 겪은 Kafka 브로커의 무한 재시작 장애와 이를 해결하기 위한 인프라 리팩토링 과정을 정리합니다.

> 🔗 **관련 PR**: [Kafka, Redis 기반 실시간 위치 스트리밍 인프라 및 기능 구현](https://github.com/ICN-Soongsil/itrc-project/pull/6)

</br>

### 리팩토링 및 학습 요약

- 배경: 도커 환경에서 카프카 브로커가 주키퍼와의 연결에 실패하고 메타데이터 오염으로 인해 무한 재시작되는 현상 발생
- 핵심: 주키퍼 상태 검증 도입을 통한 서비스 구동 순서 보장과 단일 브로커 환경에 최적화된 복제본 설정 조정
- 결과: 인프라 구성 요소 간의 논리적 의존성 확보 및 자동 복구 설정을 통한 로컬 개발 환경의 안정성 강화

</br>

### 1. 관성적인 인프라 구축에서 원리 중심의 환경 설계로

실시간 위치 데이터를 처리하기 위한 시스템을 설계하면서 가장 먼저 마주한 과제는 애플리케이션 코드가 아닌 이를 뒷받침할 인프라의 견고함이었다. 도커 컴포즈를 활용해 카프카를 실행하는 과정에서 브로커 컨테이너가 정상적으로 올라오지 못하고 종료와 재시작을 반복하는 현상을 목격했다. 

왜 카프카는 주키퍼를 찾지 못하는지, 그리고 도커 엔진은 왜 아직 부팅 중인 브로커를 죽은 프로세스로 간주하는지에 대한 의구심이 생겼다. 이 과정을 통해 인프라 설정을 단순한 텍스트 뭉치가 아니라 각 서비스가 생명 주기를 공유하는 유기적인 설계도로 인식하게 되었다. 단순한 관성에서 벗어나 분산 시스템의 구성 요소가 서로를 인지하는 방식을 탐구하기 시작했다.

</br>

### 2. 도커는 프로세스의 '준비'를 기다려주지 않는다: 실행 컨텍스트와 순서 제어

가장 먼저 점검한 것은 아주 기초적인 실행 환경이었다. 도커 명령어를 실행하는 위치가 프로젝트의 루트 경로가 아닐 경우, 설정 파일이 유실되거나 엉뚱한 경로에 데이터 볼륨이 생성되는 문제를 발견했다. 실행 컨텍스트를 올바르게 고정하는 것부터가 트래블슈팅의 시작이었다.

또한 비정상적인 종료 이후 남아있는 잔재들이 다음 실행에 미치는 영향을 확인했다. 이전에 사용하던 볼륨에 남겨진 로그 세그먼트나 체크포인트 파일이 새롭게 할당된 브로커 아이디와 충돌을 일으키면 카프카는 정합성 문제로 인해 기동을 거부한다. 이를 해결하기 위해 기존 상태를 완전히 소거하는 클린 스테이트 확보 작업을 선행했다.

```yaml
# 1. 실행 경로 이동을 통한 컨텍스트 고정
cd ~/Git/itrc-project

# 2. 볼륨 데이터까지 완전히 포함하여 컨테이너와 네트워크 제거
docker-compose down -v

# 3. 호스트 기기에서 충돌 가능성이 있는 포트 점유 프로세스 정리
lsof -i :9092
kill -9 [PID]
```

</br>

단순히 물리적인 포트를 비우고 파일을 지우는 것만으로는 부족했다. 도커 컴포즈에서 제공하는 의존성 설정은 컨테이너의 생성 순서만을 제어할 뿐, 그 안에서 돌아가는 애플리케이션의 준비 상태를 보장하지 않는다. 주키퍼가 네트워크 요청을 처리할 수 있는 상태가 되었을 때 비로소 카프카가 시작되도록 상태 검증 로직을 강화했다.

```yaml
version: '3.8'

services:
  # 1. Zookeeper: Kafka의 메타데이터 관리 및 클러스터 상태 조율
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "2181" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # 2. Kafka: 고빈도 위치 이벤트를 수집하고 전달하는 스트리밍 브로커
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    restart: always
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://${KAFKA_EXTERNAL_HOST:-localhost}:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # [안정성 강화] 싱글 브로커 환경 필수 설정
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

    # [헬스체크 추가] 카프카가 실제로 준비될 때까지 스프링의 접근을 제어
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s

  # 3. Redis: 최신 위치 상태를 유지하는 고속 인메모리 DB
  redis:
    image: redis/redis-stack:7.4.0-v6
    ports:
      - "6379:6379"
      - "127.0.0.1:8001:8001"
    command: redis-server --save ""
```

위 설정에서 특히 유심히 살펴본 부분은 `start_period` 설정이다. 카프카는 자바 가상 머신 위에서 동작하며 내부적으로 메타데이터를 로딩하고 컨트롤러를 선출하는 복잡한 과정을 거친다. 도커 엔진이 이 초기화 시간을 기다려주지 않으면, 아직 준비 중인 카프카를 비정상으로 판단하여 컨테이너를 강제 재시작하는 무한 루프에 빠지게 된다. 40초의 유예 기간은 시스템이 스스로 자리를 잡고 외부에 서비스를 제공할 수 있을 때까지 기다려주는 최소한의 안전장치임을 이해하게 되었다.

</br>

### 3. 분산 시스템의 원칙과 로컬의 타협: 단일 브로커 환경의 정합성 확보

카프카 클러스터의 운용에서 주키퍼는 단순한 저장소 이상의 역할을 수행한다. 분산 환경에서 여러 브로커가 협업하기 위한 지도를 관리하며, 리더 선출 작업을 돕거나 토픽 생성 정보와 같은 핵심 메타데이터를 동기화하는 중앙 통제실과 같다. 브로커가 기동될 때 가장 먼저 수행하는 작업이 주키퍼에 접속하여 자신의 존재를 에페머럴 노드로 등록하는 것인 만큼, 주키퍼의 가용성은 곧 카프카 전체의 생존과 직결된다.

또한 카프카는 태생적으로 고가용성을 위해 3개 이상의 브로커를 가정하고 설계되었다. 로컬 개발 환경처럼 단일 브로커를 사용하는 상황에서는 기본 설정값이 오히려 독이 될 수 있다. 오프셋 토픽이나 트랜잭션 로그 토픽의 복제본 계수가 기본값인 3으로 설정되어 있으면, 카프카는 존재하지 않는 나머지 2대의 브로커를 찾으며 정상적인 동작을 시작하지 못한다.

이때 리플리케이션 팩터 설정을 1로 조정하는 과정은 단순히 에러를 회피하는 수단이 아니다. 이는 인프라의 물리적 한계를 인지하고 그에 맞는 소프트웨어 정책을 수립하여 시스템의 정합성을 맞추는 엔지니어링 의사결정이다. 내부 동작 원리를 파고들며 설정 하나하나가 시스템 전체의 런타임 객체 관계에 어떤 무게를 갖는지 체감할 수 있었다.

</br>

### 4. 마치며: 견고한 실행 환경이 주는 시스템의 예측 가능성

이번 트래블슈팅 과정을 통해 분산 시스템의 각 컴포넌트가 맺고 있는 유기적인 관계를 깊이 이해할 수 있었다. 주키퍼는 단순한 부가 서비스가 아니라 카프카의 뇌 역할을 수행하며, 이들 사이의 선후 관계를 상태 검증이라는 논리적 도구로 묶어주는 것이 엔지니어의 핵심 역량임을 깨달았다.

인프라의 안정성이 확보되었을 때 비로소 비즈니스 로직을 담은 코드가 힘을 발휘할 수 있다는 사실을 다시금 새겼다. 이제 흔들리지 않는 메시징 브로커 환경이 갖춰졌으므로, 이 토대 위에 데이터를 안정적으로 적재하고 처리할 시스템을 구축할 준비가 되었다.
