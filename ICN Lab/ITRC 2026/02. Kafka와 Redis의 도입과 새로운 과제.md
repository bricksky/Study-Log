## 1. 아키텍처 전환의 동기

---

1주차 연구를 통해 RDBMS(PostgreSQL/PostGIS)가 고빈도 위치 데이터 업데이트와 대규모 폴링 상황에서 발생하는 락 경합 및 I/O 병목을 감당하기 어렵다는 것을 확인했다. 이를 해결하기 위한 업계의 표준적인 대안은 Apache Kafka를 이벤트 스트리밍 통로로 활용하고, Redis를 실시간 조회를 위한 고속 저장소로 사용하는 하이브리드 아키텍처다.

- **Apache Kafka:** 대용량의 이벤트를 실시간으로 전달하는 '중간 다리(메시지 브로커)'다. 라이더의 위치 이벤트를 아주 빠르게 받아서 필요한 곳에 뿌려주는 역할을 한다. 단순히 메시지를 전달하는 큐의 역할을 넘어, 들어온 데이터를 순서대로 기록하고 이를 여러 서비스가 동시에 읽어갈 수 있게 해준다.
- **Redis:** 모든 데이터를 디스크가 아닌 주 기억 장치(RAM)에 저장하는 오픈소스 인메모리 데이터 구조 저장소다. Key-Value 형태로 데이터를 저장하며, 메모리 접근 특성상 응답 속도가 1ms(밀리초) 미만인 Sub-millisecond 성능을 보장한다. RDBMS의 무거운 물리 연산을 대체하여 실시간 위치 조회를 가속화하는 데 최적이다.디스크를 거치지 않으니 속도가 말도 안 되게 빠르다.
- **트레이드오프 :** 하나를 얻으면 하나를 잃는 관계. 예를 들어, 속도를 얻기 위해 시스템의 복잡성을 감수하는 상황을 말한다. LBS 아키텍처에서 “속도를 높이기 위해(Redis 도입) 시스템 구조가 복잡해지고 데이터가 일시적으로 불일치할 위험을 감수하는 것"이 전형적인 트레이드오프의 사례다.
- **메시지 브로커:** 송신자로부터 메시지를 받아 수신자에게 전달해주는 중간 매개체다. 송신자와 수신자가 직접 연결되지 않아도 되므로, 한쪽 서버에 장애가 나거나 부하가 몰려도 전체 시스템이 멈추지 않도록 완충 작용을 해준다.

</br>

### 1.1 왜 Kafka와 Redis의 조합인가?

<img width="715" height="394" alt="image" src="https://github.com/user-attachments/assets/404a3951-9c17-4401-9a59-c4cf2f35f152" />


전통적인 구조에서는 DB가 '저장'과 '전달'의 역할을 모두 수행했지만, 현대적인 아키텍처에서는 이를 분리한다.

- **전달의 최적화 (Kafka):** 수만 명의 라이더가 쏘는 위치 좌표를 DB에 바로 쓰지 않고, 일단 Kafka라는 거대한 데이터 파이프라인에 던진다. Kafka는 이를 아주 빠르게 수집하여 필요한 시스템(알림 서버, 배차 엔진 등)에 실시간으로 뿌려준다. 이 과정에서 DB의 쓰기 부하가 획기적으로 줄어든다.
- **조회의 최적화 (Redis):** "내 주변 라이더 찾기"와 같은 빈번한 조회 요청은 RDBMS가 아닌 Redis가 처리한다. 모든 데이터를 메모리(RAM)에 들고 있기 때문에, 디스크를 읽어야 하는 RDBMS와는 비교할 수 없는 속도로 응답할 수 있다.

</br>

### 1.2 도입 과정에서의 현실적인 문제: 트레이드오프

단순히 "빠른 도구들을 쓰면 성능이 좋아질 것"이라는 기대와 달리, 실제 구현 단계에서는 예상치 못한 복잡성이 발생했다.

1. **설치 및 운영의 난이도:** Kafka는 브로커(Broker) 관리부터 파티션 설계까지 매우 까다로운 운영 지식을 요구한다.
2. **데이터 정합성 유지:** DB와 Redis, Kafka 세 곳의 데이터를 어떻게 동일하게 맞출 것인가 라는 고난도 과제가 주어진다.
3. **시스템 복잡도 증가:** 관리해야 할 서버와 소프트웨어가 늘어남에 따라 장애 발생 포인트도 함께 늘어난다.

연구를 진행하며 깨달은 가장 중요한 점은, 어떤 기술도 모든 문제를 해결해주는 것이 아니라는 것이다. 성능을 얻는 대신 운영의 복잡성을 지불해야 하는 트레이드오프 관계를 정확히 분석하는 것이 이번 연구의 핵심 과제다.

</br>
</br>
</br>

## 2. 첫 번째 장벽: "배보다 배꼽이 더 크다"- 분산 시스템 운영의 복잡성

먼저 Kafka를 도입하려고 문서를 찾아봤다. 그런데 단순히 프로그램 하나 띄운다고 끝나는 게 아니었다.

Kafka를 제대로 돌리려면 브로커 클러스터를 구성해야 하고, 이를 관리하기 위한 ZooKeeper라는 별도의 관리 프로그램도 필요했다. (최근엔 KRaft로 대체되기도 하지만 여전히 복잡하다.)

특히 위치 데이터처럼 잠깐 쓰이고 버려지는 데이터에 대해, 모든 내용을 디스크에 기록하는 Kafka의 방식이 과연 최선일까? 라는 의문이 들었다.

- **메시지 브로커:** 서비스와 서비스 사이에서 데이터를 중간에 중계해 주는 시스템이다. 데이터를 보내는 쪽과 받는 쪽이 서로의 주소나 상태를 알 필요 없이 브로커에만 던지면 되기 때문에, 시스템 간의 결합도를 낮추는 핵심 역할을 한다.
- **클러스터**: 여러 대의 컴퓨터를 연결해 마치 하나의 시스템처럼 동작하게 만드는 것. 특정 서버에 장애가 발생해도 다른 서버가 즉시 업무를 대신 수행할 수 있게 하여 시스템의 중단 없는 서비스를 보장한다.
- **오버헤드:** 어떤 기능을 구현하기 위해 직접적으로 필요한 작업 외에, 그 환경을 유지하고 관리하기 위해 추가적으로 소모되는 시간, 인력, 비용 등의 자원을 말한다. Kafka의 경우 브로커 설정, 파티션 관리, 모니터링 시스템 구축 등이 여기에 해당한다.
- **브로커:** Kafka 시스템 내에서 실제로 데이터를 수신하고, 저장하며, 소비자에게 전달하는 역할을 수행하는 각각의 서버 단위를 의미한다. 보통 데이터 유실 방지를 위해 최소 3대 이상의 브로커로 클러스터를 구성하는 것이 권장된다.
- **ZooKeeper / KRaft:** 분산된 환경에서 서버들 간의 정보를 공유하고 상태를 관리하는 일종의 '관리자' 역할이다. ZooKeeper는 외부 별도 시스템이고, KRaft는 Kafka 내부에 이 관리 기능을 내장시킨 최신 방식이다.

</br>

### 2.1 Kafka의 구조적 복잡성: 브로커와 클러스터

Kafka를 공부하며 가장 당황스러웠던 점은 프로그램 하나만 실행해서는 아무것도 할 수 없다는 사실이었다.

- **브로커(Broker)와 클러스터(Cluster):** Kafka는 기본적으로 여러 대의 서버(브로커)를 묶어 하나의 거대한 저장소(클러스터)처럼 동작시킨다. 이는 데이터의 유실을 막고(고가용성), 부하를 분산하기 위함이다. 하지만 학부 수준의 연구 프로젝트에서 3대 이상의 브로커를 띄우고 관리하는 것은 자원과 시간 면에서 큰 **오버헤드**였다.
- **메타데이터 관리의 이중화 (ZooKeeper/KRaft):** Kafka 브로커들은 스스로 "누가 리더인지", "데이터가 어디에 저장되어 있는지"를 알지 못한다. 이를 관리하기 위해 과거에는 **ZooKeeper**라는 별도의 클러스터 관리 프로그램이 필수였다. 최근에는 Kafka 내부에 이를 통합한 **KRaft** 방식이 나왔지만, 여전히 합의 알고리즘(Raft) 등 복잡한 분산 시스템 이론을 이해해야만 안정적인 운영이 가능하다.

</br>

### 2.2 저장 방식의 의문: 휘발성 데이터와 디스크 영속성

연구를 진행하며 가장 의구심이 들었던 부분은 Kafka의 **데이터 저장 방식**이다.

- **디스크 기반 저장 (Persistence):** Kafka는 들어오는 모든 데이터를 디스크(Disk)에 순차적으로 기록한다. 이는 시스템이 멈췄을 때 데이터를 복구하기 위한 훌륭한 장치다.
- **LBS 데이터와의 부조화:** 하지만 내가 다루는 라이더의 GPS 좌표는 **'휘발성 데이터'**다. 10초 전의 위치 정보는 기록할 가치가 거의 없으며, 시스템이 복구되었을 때 과거의 위치를 다시 읽어오는 것보다 현재의 최신 위치를 받는 것이 훨씬 중요하다.

</br>
</br>
</br>

## 3. 두 번째 장벽: "두 군데에 똑같이 쓰기 어렵다" (이중 쓰기 문제)

---

RDBMS의 느린 속도를 해결하기 위해, 가장 먼저 떠올린 아이디어는 '역할 분담'이었다. 실시간 위치 조회처럼 빠른 응답이 필요한 작업은 **Redis**가 담당하고, 결제나 정산처럼 영구 보관이 필요한 최종 데이터는 **RDBMS**가 담당하는 구조다. 하지만 이 설계는 이중 쓰기라는 거대한 정합성 문제에 직면하게 되었다. 

- **상황:** Redis에는 위치가 잘 저장됐는데, 갑자기 DB 서버에 문제가 생겨서 저장이 안 된다면?
- **결과:** 실시간 지도(Redis 기반)에는 라이더가 강남역에 있다고 나오는데, 나중에 결제나 기록 확인(DB 기반)을 해보면 라이더가 엉뚱한 곳에 있었다고 기록될 수 있다.

이런 데이터 불일치를 막으려면 분산 트랜잭션 같은 복잡한 기술이 필요한데, 이건 시스템을 더 느리게 만든다. 

- **이중 쓰기:** 애플리케이션 레벨에서 하나의 데이터를 두 개 이상의 서로 다른 저장소(예: Redis와 PostgreSQL)에 각각 기록하는 행위다. 저장소 간의 트랜잭션이 보장되지 않기 때문에, 일부 저장소에만 기록이 성공하고 나머지는 실패하는 상황이 발생할 위험이 상존한다.
- **데이터 정합성:** 여러 개의 시스템이나 저장소에 흩어져 있는 동일한 데이터가 서로 모순 없이 일치하는 상태를 말한다. 실시간 서비스에서는 속도와 정합성이 상충하는 경우가 많으며, 어떤 상황에서도 데이터가 틀리지 않아야 하는 '강한 정합성'과 시간이 흐르면 결과적으로 일치하게 되는 '최종 정합성' 중 하나를 선택해야 한다.
- **분산 트랜잭션:** 네트워크로 연결된 두 개 이상의 독립적인 시스템(저장소)에서 수행되는 작업들을 하나의 원자적 단위로 묶는 기술이다. 모든 참여자가 성공해야만 최종 승인이 이루어지며, 이를 보장하기 위해 2PC(2-Phase Commit) 같은 복잡한 프로토콜을 사용한다. 하지만 구현 난이도가 매우 높고 시스템 가용성을 떨어뜨리는 주범이 된다.
- **원자성:** 트랜잭션 내의 모든 작업이 '전부 성공하거나, 아니면 아예 실행되지 않은 상태'여야 함을 뜻하는 ACID의 첫 번째 원칙이다. 이중 쓰기 구조에서는 이 원자성을 보장하기가 매우 까다롭기 때문에 시스템 설계 시 가장 먼저 고려해야 할 요소다.
- **경쟁 상태:** 여러 개의 트랜잭션이나 스레드가 동시에 같은 데이터를 수정하려고 할 때, 실행 순서에 따라 결과가 달라지는 현상이다. Redis와 DB를 업데이트하는 순서가 꼬일 경우, 나중에 발생한 위치 이벤트가 먼저 처리되어 과거의 위치가 최종 데이터로 남는 문제가 발생할 수 있다.
- **최종 정합성:** 실시간으로 데이터가 일치하지 않더라도, 시스템에 더 이상의 변경이 없다면 시간이 흐른 뒤에는 모든 복제본이 동일한 값으로 수렴한다는 개념이다. 초고속 처리가 중요한 LBS 아키텍처에서는 강한 정합성 대신 이 방식을 택하고, 대신 불일치 시간을 최소화하는 전략을 주로 사용한다.

</br>

### 3.1 이중 쓰기의 메커니즘과 실패 시나리오

서버가 라이더의 위치 좌표를 받으면, 원칙적으로 두 저장소를 모두 업데이트해야 한다.
서버는 **1) Redis 업데이트**와 **2) DB 저장**을 동시에 해야 한다.

여기서 이중 쓰기 문제가 터진다.

1. **Step 1:** Redis에 라이더의 최신 좌표를 업데이트한다. (실시간 지도 표시용)
2. **Step 2:** RDBMS에 해당 위치 기록을 저장한다. (추후 정산 및 경로 확인용)

문제는 이 두 단계가 '하나의 묶음’으로 실행되지 않는다는 점이다. 만약 Step 1은 성공했는데, 그 직후 네트워크 장애나 DB 서버의 과부하로 Step 2가 실패한다면 시스템은 치명적인 불일치 상태에 빠진다.

- **결과:** 사용자의 화면(Redis 기반)에서는 라이더가 목적지에 도착한 것으로 보이지만, 시스템 관리자가 DB를 조회하면 라이더가 아직 출발지에 있는 것으로 기록될 수 있다. 이러한 데이터 불일치는 단순한 오류를 넘어 서비스의 신뢰도를 무너뜨리는 결과를 초래한다.

</br>

### 3.2 해결의 딜레마: 분산 트랜잭션의 비용

이 문제를 해결하기 위해 두 저장소의 업데이트를 하나로 묶으려는 시도를 검토해 보았다. 이를 분산 트랜잭션이라 한다.

- **2단계 커밋(2PC):** Redis와 DB 모두에게 "준비됐니?"라고 묻고, 둘 다 "OK"를 하면 그때서야 데이터를 확정 짓는 방식이다.
- **성능의 역설:** 하지만 이 방식은 두 저장소가 모두 응답할 때까지 서버가 대기해야 하므로 지연 시간이 폭발적으로 늘어난다. 실시간성을 확보하려고 Redis를 도입했는데, 정합성을 맞추기 위해 다시 RDBMS보다 느린 시스템을 만들게 되는 셈이다.

</br>
</br>
</br>

## 4. 세 번째 장벽: "SQL이 그립다" (복잡한 쿼리의 한계)

---

마지막으로 Redis의 가장 아쉬운 점을 발견했다. 바로 쿼리의 유연성이다.

PostgreSQL에서는 "서울 강남구에 있고, 평점이 4.5 이상이며, 현재 배달 가능 상태인 라이더"를 SQL 한 줄로 찾을 수 있다. 하지만 Redis는 기본적으로 Key-Value 형태다.
`GEOSEARCH`라는 위치 찾기 기능이 있긴 하지만, 여기에 "평점 4.5 이상" 같은 복합적인 조건을 섞어서 검색하는 게 너무 힘들다. 결국 데이터를 다 가져와서 서버 애플리케이션 코드 상에서 일일이 걸러내야 하는데, 이건 네트워크 대역폭을 낭비하고 코드를 지저분하게 만든다.

- **Key-Value Store:** 이름(Key)과 값(Value)이 쌍으로 저장되는 단순한 구조의 데이터베이스다. 마치 사전에서 단어를 찾으면 뜻이 나오는 것과 같은 원리다. 구조가 단순한 만큼 조회 속도가 극도로 빠르지만, SQL처럼 데이터 간의 복잡한 관계를 계산하거나 여러 조건을 동시에 검색하는 기능은 매우 제한적이다.
- **필터링:** 전체 데이터 집합에서 특정 조건에 맞는 데이터만 골라내는 작업이다. 효율적인 시스템은 이 작업을 '데이터가 저장된 곳(DB)'에서 처리하여 필요한 결과만 전송하지만, Redis와 같은 단순 저장소에서는 '데이터를 사용하는 곳'으로 모든 데이터를 가져와 거르는 비효율이 발생하기 쉽다.
- **네트워크 대역폭:** 네트워크 통신을 통해 한 번에 보낼 수 있는 데이터 양을 의미한다. 위치 기반 서비스처럼 통신이 잦은 시스템에서는 '불필요한 데이터 전송'을 줄이는 것이 핵심이다. 위에서 언급한 '과다 조회'는 이 대역폭을 점유하여 다른 중요한 통신을 방해하고 서비스 지연을 유발한다.
- **스키마:** 데이터베이스에서 데이터가 저장되는 구조와 제약 조건을 정의한 설계도다. RDBMS는 엄격한 스키마를 통해 데이터의 형식을 강제하고 인덱스를 최적화하지만, Redis 같은 NoSQL은 스키마가 없거나 유연하여 자유로운 대신 복잡한 질의를 수행하는 능력은 떨어진다.

</br>

### 4.1 스키마 기반 RDBMS vs 스키마리스 Key-Value 저장소

PostgreSQL과 같은 RDBMS는 정교한 스키마를 바탕으로 동작한다.

- **RDBMS의 강점:** "서울 강남구(위치) + 평점 4.5 이상(속성) + 배달 가능(상태)"이라는 조건을 SQL의 `WHERE` 절에 넣으면, DB 엔진은 미리 구축된 공간 인덱스와 일반 인덱스를 조합하여 최적의 결과만을 뽑아준다.
- **Redis의 한계:** Redis는 기본적으로 **Key-Value** 구조다. 특정 키에 대한 값을 가져오는 데는 최적화되어 있지만, 여러 속성이 섞인 복합 조건을 처리하는 '지능'은 부족하다. Redis의 `GEOSEARCH`는 오직 '위치' 정보만을 기준으로 검색하며, 여기에 '평점'이나 '상태' 같은 다른 필드 조건을 동시에 걸 수 있는 네이티브 기능이 없다.

</br>

### 4.2 애플리케이션 레벨 필터링의 비효율성: "가져와서 거르기"

Redis에서 복합 조건을 만족하는 라이더를 찾으려면, 결국 개발자는 다음과 같은 비효율적인 우회 방법을 선택하게 된다.

1. **Over-fetching (과다 조회):** 먼저 Redis의 `GEOSEARCH`를 통해 반경 1km 이내의 모든 라이더(예: 1,000명)를 서버로 가져온다.
2. **Application Filtering:** 서버 애플리케이션 코드 내에서 반복문을 돌리며 "평점 4.5 이상인가?", "배달 가능 상태인가?"를 일일이 검사한다.
3. **결과 도출:** 최종적으로 조건에 맞는 10명만을 남긴다.

이 과정에서 발생하는 문제는 명확하다. 실제 필요한 데이터는 10건뿐인데, 네트워크를 통해 1,000건의 데이터를 전송해야 하므로 네트워크 대역폭이 낭비된다. 또한, DB가 해야 할 필터링 연산을 서버의 CPU가 대신 수행하게 되면서 서버의 부담이 가중된다.

</br>

### 4.3 데이터 모델링의 난제: 인덱스 직접 구현하기

이런 비효율을 줄이려고 Redis에서 '상태별 집합(Set)'을 따로 만들어 관리하는 방법도 있다. 하지만 이 방식은 라이더의 상태가 바뀔 때마다 여러 집합을 동시에 업데이트해야 하므로 2.3에서 언급한 정합성 문제를 더욱 악화시킨다. "성능을 위해 단순한 저장소를 선택했는데, 정작 기능을 구현하려니 훨씬 더 복잡한 로직을 직접 코딩해야 한다"는 역설적인 상황에 직면하게 된 것이다.

</br>
</br>
</br>

## 5. 결론: "속도와 정합성, 그리고 편의성 사이의 고민"

---

이번 공부를 통해 깨달은 것은, Kafka와 Redis를 도입한다고 해서 모든 문제가 해결되지는 않는다는 사실이다.

1. Kafka는 너무 거대하고 운영하기 어렵다.
2. 이중 쓰기는 데이터 정합성을 위협한다.
3. Redis는 빠르지만, SQL처럼 똑똑하게 검색하기 힘들다.

</br>

### 5.1 연구 요약: 세 가지 벽

현대적인 기술 스택으로의 전환 과정에서 확인한 핵심 문제점들은 다음과 같다.

1. **관리의 벽 (Kafka):** 대규모 로그 처리에 최적화된 Kafka는 소규모 서비스에서 운영하기에는 인프라 오버헤드가 너무 컸다. 또한, 1초 뒤면 사라질 휘발성 GPS 데이터를 굳이 디스크에 기록해야 하는가에 대한 구조적 회의감이 들었다.
2. **신뢰의 벽 (Dual-Write):** Redis와 RDBMS를 혼용하는 구조는 필수적으로 데이터 불일치 문제를 야기한다. 이를 해결하기 위해 분산 트랜잭션을 도입하면 성능이 다시 RDBMS 수준으로 회귀하고, 도입하지 않으면 데이터의 정합성이 무너지는 딜레마를 확인했다.
3. **기능의 벽 (Querying):** Redis는 빨랐지만 '똑똑하지' 않았다. SQL의 유연한 복합 질의 능력을 포기한 대가로, 모든 필터링 로직을 서버 애플리케이션 코드로 가져와야 했으며, 이는 네트워크 대역폭 낭비와 코드 복잡도 상승으로 이어졌다.

</br>

### 5.2 연구를 위한 새로운 이정표

결국 "어떻게 하면 운영은 가볍게 가져가면서, 데이터는 똑똑하게 처리하고, 공간 연산은 더 정확하게 할 수 있을까?"가 내 연구의 최종 목적지가 되었다. 

이 문제들을 해결하기 위해 다음에는 Redis Streams라는 좀 더 가벼운 이벤트 도구와, RediSearch라는 복합 검색 엔진을 파헤쳐 보려 한다. 또한, 단순히 사각형으로 지도를 나누는 Geohash의 한계를 극복하기 위해 Uber에서 만든 H3(육각형 인덱스)라는 것도 공부 리스트에 넣었다.
